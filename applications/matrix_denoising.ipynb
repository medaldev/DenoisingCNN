{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:37:50.204817033Z",
     "start_time": "2023-11-06T01:37:47.754436553Z"
    }
   },
   "outputs": [],
   "source": [
    "from applications import image_denoising\n",
    "from models import ConvAutoencoderLuma\n",
    "from dataloaders import SimpleLoader2d\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = ConvAutoencoderLuma().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T00:55:21.891473991Z",
     "start_time": "2023-11-06T00:55:21.884535220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "name_model = \"model_1\"\n",
    "name_dataset = \"gcg\"\n",
    "path_base = \"/home/amedvedev/fprojects/cpp/gcg_2d_minimal/data/\"\n",
    "\n",
    "path_save_model = os.path.join(\"../assets/pt/\", f\"{name_dataset}_{name_model}.pt\")\n",
    "\n",
    "try:\n",
    "    model = torch.load(path_save_model).to(device)\n",
    "except Exception as e:\n",
    "    print(\"Error when loading pretrained model. Use custom.\")\n",
    "    model = ConvAutoencoderLuma().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:37:51.655024505Z",
     "start_time": "2023-11-06T01:37:50.210387079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "path_save_train_plots = os.path.join(\"../assets/runs/train_plots\", name_dataset, name_model)\n",
    "\n",
    "path_train = os.path.join(path_base, name_dataset, \"train\")\n",
    "path_test = os.path.join(path_base, name_dataset, \"val\")\n",
    "\n",
    "path_train_rainy = path_train + \"/noised\"\n",
    "path_test_rainy = path_test + \"/noised\"\n",
    "\n",
    "path_train_normal = path_train + \"/clear\"\n",
    "path_test_normal = path_test + \"/clear\"\n",
    "\n",
    "\n",
    "width, height = 100, 100\n",
    "\n",
    "train_noisy_loader = SimpleLoader2d(path_train_rainy, device, BATCH_SIZE, width, height)\n",
    "train_normal_loader = SimpleLoader2d(path_train_normal, device, BATCH_SIZE, width, height)\n",
    "\n",
    "val_noisy_loader =SimpleLoader2d(path_test_rainy, device, BATCH_SIZE, width, height)\n",
    "val_normal_loader =SimpleLoader2d(path_test_normal, device, BATCH_SIZE, width, height)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:37:53.454154301Z",
     "start_time": "2023-11-06T01:37:53.422539656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def plot_step_results():\n",
    "    image_denoising.save_results(model, device, path_save_train_plots, train_noisy_loader, train_normal_loader, \"train\",\n",
    "                                 limit=1, nrow=8, op_count=1)\n",
    "    image_denoising.save_results(model, device, path_save_train_plots, val_noisy_loader, val_normal_loader, \"test\",\n",
    "                                 limit=1, nrow=8, op_count=1)\n",
    "    print(f\"Step results plotted to {path_save_train_plots}.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:37:55.142664660Z",
     "start_time": "2023-11-06T01:37:55.137305732Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step results plotted to ../assets/runs/train_plots/gcg/model_1.\n",
      "Training progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Validating progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Epoch: 1 \tTraining Loss: 0.004312 \tValidating Loss: 0.001538 \tTime: 0.57 m\n",
      "Step results plotted to ../assets/runs/train_plots/gcg/model_1.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Validating progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Epoch: 2 \tTraining Loss: 0.001430 \tValidating Loss: 0.001238 \tTime: 0.57 m\n",
      "Model saved successfully at ../assets/pt/gcg_model_1.pt.\n",
      "Step results plotted to ../assets/runs/train_plots/gcg/model_1.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Validating progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 0.001175 \tValidating Loss: 0.001061 \tTime: 0.57 m\n",
      "Model saved successfully at ../assets/pt/gcg_model_1.pt.\n",
      "Step results plotted to ../assets/runs/train_plots/gcg/model_1.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Validating progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Epoch: 4 \tTraining Loss: 0.001006 \tValidating Loss: 0.000885 \tTime: 0.57 m\n",
      "Model saved successfully at ../assets/pt/gcg_model_1.pt.\n",
      "Step results plotted to ../assets/runs/train_plots/gcg/model_1.\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Validating progress: |██████████████████████████████████████████████████| 100.0% Complete | \r\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 0.000848 \tValidating Loss: 0.000775 \tTime: 0.57 m\n",
      "Model saved successfully at ../assets/pt/gcg_model_1.pt.\n",
      "Step results plotted to ../assets/runs/train_plots/gcg/model_1.\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "image_denoising.train(model, train_noisy_loader, train_normal_loader, val_noisy_loader, val_normal_loader,\n",
    "                      EPOCHS, device, path_save=path_save_model, callbacks=[plot_step_results])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:32:36.571826044Z",
     "start_time": "2023-11-06T01:29:41.567217355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/_tensor.py:836: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step results plotted to ../assets/runs/train_plots/gcg/model_1.\n"
     ]
    }
   ],
   "source": [
    "plot_step_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:20:46.539413830Z",
     "start_time": "2023-11-06T01:20:44.322567567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_denoising.save_full_model(model, path_save_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%img : Float(1, 1, 100, 100, strides=[10000, 10000, 100, 1], requires_grad=0, device=cuda:0),\n",
      "      %all_layers.0.weight : Float(76, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.0.bias : Float(76, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.3.weight : Float(38, 76, 2, 2, strides=[304, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.3.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.6.weight : Float(38, 38, 2, 2, strides=[152, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.6.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.9.weight : Float(38, 38, 2, 2, strides=[152, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.9.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.11.weight : Float(38, 76, 2, 2, strides=[304, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.11.bias : Float(76, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.13.weight : Float(76, 1, 2, 2, strides=[4, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.13.bias : Float(1, strides=[1], requires_grad=1, device=cuda:0)):\n",
      "  %/all_layers/all_layers.0/Conv_output_0 : Float(1, 76, 100, 100, strides=[760000, 10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/all_layers/all_layers.0/Conv\"](%img, %all_layers.0.weight, %all_layers.0.bias), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.Conv2d::all_layers.0 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/all_layers/all_layers.1/Relu_output_0 : Float(1, 76, 100, 100, strides=[760000, 10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.1/Relu\"](%/all_layers/all_layers.0/Conv_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.1 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.2/MaxPool_output_0 : Float(1, 76, 99, 99, strides=[744876, 9801, 99, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.2/MaxPool\"](%/all_layers/all_layers.1/Relu_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.pooling.MaxPool2d::all_layers.2 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/all_layers/all_layers.3/Conv_output_0 : Float(1, 38, 98, 98, strides=[364952, 9604, 98, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.3/Conv\"](%/all_layers/all_layers.2/MaxPool_output_0, %all_layers.3.weight, %all_layers.3.bias), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.Conv2d::all_layers.3 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/all_layers/all_layers.4/Relu_output_0 : Float(1, 38, 98, 98, strides=[364952, 9604, 98, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.4/Relu\"](%/all_layers/all_layers.3/Conv_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.4 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.5/MaxPool_output_0 : Float(1, 38, 97, 97, strides=[357542, 9409, 97, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.5/MaxPool\"](%/all_layers/all_layers.4/Relu_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.pooling.MaxPool2d::all_layers.5 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/all_layers/all_layers.6/Conv_output_0 : Float(1, 38, 96, 96, strides=[350208, 9216, 96, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.6/Conv\"](%/all_layers/all_layers.5/MaxPool_output_0, %all_layers.6.weight, %all_layers.6.bias), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.Conv2d::all_layers.6 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/all_layers/all_layers.7/Relu_output_0 : Float(1, 38, 96, 96, strides=[350208, 9216, 96, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.7/Relu\"](%/all_layers/all_layers.6/Conv_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.7 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.8/MaxPool_output_0 : Float(1, 38, 97, 97, strides=[357542, 9409, 97, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/all_layers/all_layers.8/MaxPool\"](%/all_layers/all_layers.7/Relu_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.pooling.MaxPool2d::all_layers.8 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/all_layers/all_layers.9/ConvTranspose_output_0 : Float(1, 38, 98, 98, strides=[364952, 9604, 98, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.9/ConvTranspose\"](%/all_layers/all_layers.8/MaxPool_output_0, %all_layers.9.weight, %all_layers.9.bias), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.ConvTranspose2d::all_layers.9 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:952:0\n",
      "  %/all_layers/all_layers.10/Relu_output_0 : Float(1, 38, 98, 98, strides=[364952, 9604, 98, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.10/Relu\"](%/all_layers/all_layers.9/ConvTranspose_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.10 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.11/ConvTranspose_output_0 : Float(1, 76, 99, 99, strides=[744876, 9801, 99, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.11/ConvTranspose\"](%/all_layers/all_layers.10/Relu_output_0, %all_layers.11.weight, %all_layers.11.bias), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.ConvTranspose2d::all_layers.11 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:952:0\n",
      "  %/all_layers/all_layers.12/Relu_output_0 : Float(1, 76, 99, 99, strides=[744876, 9801, 99, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.12/Relu\"](%/all_layers/all_layers.11/ConvTranspose_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.12 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.13/ConvTranspose_output_0 : Float(1, 1, 100, 100, strides=[10000, 10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.13/ConvTranspose\"](%/all_layers/all_layers.12/Relu_output_0, %all_layers.13.weight, %all_layers.13.bias), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.ConvTranspose2d::all_layers.13 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:952:0\n",
      "  %output : Float(1, 1, 100, 100, strides=[10000, 10000, 100, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name=\"/all_layers/all_layers.14/Sigmoid\"](%/all_layers/all_layers.13/ConvTranspose_output_0), scope: models.ConvAutoEncoder.ConvAutoencoderLuma::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.Sigmoid::all_layers.14 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:292:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_save_model_onnx = os.path.join(\"../assets/onnx/\", f\"{name_dataset}_{name_model}.onnx\")\n",
    "inp = torch.randn((1, 1, width, height), device=device)\n",
    "image_denoising.save_onnx_model(model, path_save_model_onnx, inp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:38:25.390184229Z",
     "start_time": "2023-11-06T01:38:24.242253488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model.cpu()\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T01:35:35.223521782Z",
     "start_time": "2023-11-06T01:35:35.220468944Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
