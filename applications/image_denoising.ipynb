{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:47:58.991180409Z",
     "start_time": "2023-11-05T19:47:57.145658819Z"
    }
   },
   "outputs": [],
   "source": [
    "from applications import image_denoising\n",
    "from models import ConvAutoencoder\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "model = ConvAutoencoder().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:47:51.319739188Z",
     "start_time": "2023-11-05T19:47:49.799280227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "name_model = \"model_1\"\n",
    "name_dataset = \"rain800_idcgan\"\n",
    "path_base = \"/home/amedvedev/fprojects/data/\"\n",
    "\n",
    "path_save_model = os.path.join(\"../assets/pt/\", f\"{name_dataset}_{name_model}.pt\")\n",
    "\n",
    "try:\n",
    "    model = torch.load(path_save_model).to(device)\n",
    "except Exception as e:\n",
    "    print(\"Error when loading pretrained model. Use custom.\")\n",
    "    model = ConvAutoencoder().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:01.519321053Z",
     "start_time": "2023-11-05T19:47:59.904664260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "path_save_train_plots = os.path.join(\"../assets/runs/train_plots\", name_dataset, name_model)\n",
    "\n",
    "path_train = os.path.join(path_base, name_dataset, \"training\")\n",
    "path_test = os.path.join(path_base, name_dataset, \"test\")\n",
    "\n",
    "path_train_rainy = path_train + \"_rainy\"\n",
    "path_test_rainy = path_test + \"_rainy\"\n",
    "\n",
    "path_train_normal = path_train + \"_normal\"\n",
    "path_test_normal = path_test + \"_normal\"\n",
    "\n",
    "(train_noisy_loader, train_normal_loader), (val_noisy_loader, val_normal_loader) = image_denoising.get_loaders(\n",
    "    path_train_rainy, path_test_rainy, path_train_normal, path_test_normal, BATCH_SIZE, device\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:02.699987996Z",
     "start_time": "2023-11-05T19:48:02.685542800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def plot_step_results():\n",
    "    image_denoising.save_results(model, device, path_save_train_plots, train_noisy_loader, train_normal_loader, \"train\",\n",
    "                                 limit=1, nrow=8, op_count=1)\n",
    "    image_denoising.save_results(model, device, path_save_train_plots, val_noisy_loader, val_normal_loader, \"test\",\n",
    "                                 limit=1, nrow=8, op_count=1)\n",
    "    print(f\"Step results plotted to {path_save_train_plots}.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:06.606959591Z",
     "start_time": "2023-11-05T19:48:06.600557225Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step results plotted to ../assets/runs/train_plots/rain800_idcgan/model_1.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NVML_SUCCESS == DriverAPI::get()->nvmlInit_v2_() INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":1123, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m EPOCHS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mimage_denoising\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_noisy_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_normal_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_noisy_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_normal_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_save\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_save_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mplot_step_results\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/fprojects/python/denoising/applications/image_denoising.py:118\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_noisy_loader, train_normal_loader, test_noisy_loader, test_normal_loader, n_epochs, device, path_save, criterion, optimizer, callbacks)\u001B[0m\n\u001B[1;32m    116\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(images_noisy)\n\u001B[1;32m    117\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, images_normal)\n\u001B[0;32m--> 118\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    121\u001B[0m loss_deltha \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m images_noisy\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: NVML_SUCCESS == DriverAPI::get()->nvmlInit_v2_() INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":1123, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "image_denoising.train(model, train_noisy_loader, train_normal_loader, val_noisy_loader, val_normal_loader,\n",
    "                      EPOCHS, device, path_save=path_save_model, callbacks=[plot_step_results])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:12.394426637Z",
     "start_time": "2023-11-05T19:48:07.796321276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "plot_step_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T17:15:17.925151502Z",
     "start_time": "2023-11-05T17:15:10.737986018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "image_denoising.save_full_model(model, path_save_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:46:21.621945433Z",
     "start_time": "2023-11-05T19:46:21.579662409Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%img : Float(1, 3, 230, 230, strides=[158700, 52900, 230, 1], requires_grad=0, device=cuda:0),\n",
      "      %all_layers.0.weight : Float(76, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.0.bias : Float(76, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.3.weight : Float(38, 76, 2, 2, strides=[304, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.3.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.6.weight : Float(38, 38, 2, 2, strides=[152, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.6.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.9.weight : Float(38, 38, 2, 2, strides=[152, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.9.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.11.weight : Float(38, 76, 2, 2, strides=[304, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.11.bias : Float(76, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.13.weight : Float(76, 3, 2, 2, strides=[12, 4, 2, 1], requires_grad=1, device=cuda:0),\n",
      "      %all_layers.13.bias : Float(3, strides=[1], requires_grad=1, device=cuda:0)):\n",
      "  %/all_layers/all_layers.0/Conv_output_0 : Float(1, 76, 230, 230, strides=[4020400, 52900, 230, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/all_layers/all_layers.0/Conv\"](%img, %all_layers.0.weight, %all_layers.0.bias), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.Conv2d::all_layers.0 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/all_layers/all_layers.1/Relu_output_0 : Float(1, 76, 230, 230, strides=[4020400, 52900, 230, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.1/Relu\"](%/all_layers/all_layers.0/Conv_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.1 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.2/MaxPool_output_0 : Float(1, 76, 229, 229, strides=[3985516, 52441, 229, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.2/MaxPool\"](%/all_layers/all_layers.1/Relu_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.pooling.MaxPool2d::all_layers.2 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/all_layers/all_layers.3/Conv_output_0 : Float(1, 38, 228, 228, strides=[1975392, 51984, 228, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.3/Conv\"](%/all_layers/all_layers.2/MaxPool_output_0, %all_layers.3.weight, %all_layers.3.bias), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.Conv2d::all_layers.3 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/all_layers/all_layers.4/Relu_output_0 : Float(1, 38, 228, 228, strides=[1975392, 51984, 228, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.4/Relu\"](%/all_layers/all_layers.3/Conv_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.4 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.5/MaxPool_output_0 : Float(1, 38, 227, 227, strides=[1958102, 51529, 227, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.5/MaxPool\"](%/all_layers/all_layers.4/Relu_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.pooling.MaxPool2d::all_layers.5 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/all_layers/all_layers.6/Conv_output_0 : Float(1, 38, 226, 226, strides=[1940888, 51076, 226, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.6/Conv\"](%/all_layers/all_layers.5/MaxPool_output_0, %all_layers.6.weight, %all_layers.6.bias), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.Conv2d::all_layers.6 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/all_layers/all_layers.7/Relu_output_0 : Float(1, 38, 226, 226, strides=[1940888, 51076, 226, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.7/Relu\"](%/all_layers/all_layers.6/Conv_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.7 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.8/MaxPool_output_0 : Float(1, 38, 227, 227, strides=[1958102, 51529, 227, 1], requires_grad=0, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/all_layers/all_layers.8/MaxPool\"](%/all_layers/all_layers.7/Relu_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.pooling.MaxPool2d::all_layers.8 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:791:0\n",
      "  %/all_layers/all_layers.9/ConvTranspose_output_0 : Float(1, 38, 228, 228, strides=[1975392, 51984, 228, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.9/ConvTranspose\"](%/all_layers/all_layers.8/MaxPool_output_0, %all_layers.9.weight, %all_layers.9.bias), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.ConvTranspose2d::all_layers.9 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:952:0\n",
      "  %/all_layers/all_layers.10/Relu_output_0 : Float(1, 38, 228, 228, strides=[1975392, 51984, 228, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.10/Relu\"](%/all_layers/all_layers.9/ConvTranspose_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.10 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.11/ConvTranspose_output_0 : Float(1, 76, 229, 229, strides=[3985516, 52441, 229, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.11/ConvTranspose\"](%/all_layers/all_layers.10/Relu_output_0, %all_layers.11.weight, %all_layers.11.bias), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.ConvTranspose2d::all_layers.11 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:952:0\n",
      "  %/all_layers/all_layers.12/Relu_output_0 : Float(1, 76, 229, 229, strides=[3985516, 52441, 229, 1], requires_grad=0, device=cuda:0) = onnx::Relu[onnx_name=\"/all_layers/all_layers.12/Relu\"](%/all_layers/all_layers.11/ConvTranspose_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.ReLU::all_layers.12 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/functional.py:1471:0\n",
      "  %/all_layers/all_layers.13/ConvTranspose_output_0 : Float(1, 3, 230, 230, strides=[158700, 52900, 230, 1], requires_grad=0, device=cuda:0) = onnx::ConvTranspose[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/all_layers/all_layers.13/ConvTranspose\"](%/all_layers/all_layers.12/Relu_output_0, %all_layers.13.weight, %all_layers.13.bias), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.conv.ConvTranspose2d::all_layers.13 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:952:0\n",
      "  %output : Float(1, 3, 230, 230, strides=[158700, 52900, 230, 1], requires_grad=0, device=cuda:0) = onnx::Sigmoid[onnx_name=\"/all_layers/all_layers.14/Sigmoid\"](%/all_layers/all_layers.13/ConvTranspose_output_0), scope: models.ConvAutoEncoder.ConvAutoencoder::/torch.nn.modules.container.Sequential::all_layers/torch.nn.modules.activation.Sigmoid::all_layers.14 # /home/amedvedev/fprojects/python/denoising/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:292:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_save_model_onnx = os.path.join(\"../assets/onnx/\", f\"{name_dataset}_{name_model}.onnx\")\n",
    "image_denoising.save_onnx_model(model, path_save_model_onnx, device, image_size=(230, 230))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:46:24.122884779Z",
     "start_time": "2023-11-05T19:46:24.055081104Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
